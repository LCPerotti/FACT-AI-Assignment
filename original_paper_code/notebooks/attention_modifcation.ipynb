{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "sys.path.append('..')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../data')\n",
    "# from Src.config import hf_access_token, hf_model_cache_dir # noqa: E402\n",
    "# os.environ[\"HF_HOME\"] = hf_model_cache_dir \n",
    "# import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model \"gpt2\" or \"EleutherAI/pythia-6.9b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viki/miniconda3/envs/fact/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from Src.model import ModelFactory\n",
    "model = ModelFactory.create(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then load the dataset (Warning, select the right dataset for the model you loaded). Load also the ablator class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m No subject found in the dataset \u001b[0m, proceeding with no subject data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing and computing lengths: 100%|██████████| 10000/10000 [00:44<00:00, 227.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from Src.dataset import BaseDataset\n",
    "from Src.experiment import Ablator\n",
    "\n",
    "\n",
    "dataset = BaseDataset(path = \"../data/full_data_sampled_gpt2.json\",\n",
    "                      model = model,\n",
    "                      experiment=\"copyVSfact\",\n",
    "                      no_subject=True)\n",
    "ablator = Ablator(model=model, dataset=dataset, experiment=\"copyVSfact\", batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the heads that you want to modify, the value to multiply the heads and the token position that you want to modify (all, or attribute):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cofa_heads = [(7, 10), (9, 9), (9, 6), (10, 0)]\n",
    "fa_heads = [(10, 7), (11, 10), (11, 3)]\n",
    "\n",
    "betas = [1, 0]\n",
    "alphas = [1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ablator.set_heads(heads=[(10, 3)], value=2, position='attribute')\n",
    "# print(ablator.model.model.hook_dict.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the attention modification:\n",
    "\n",
    "\n",
    "- mem --> logit of the factual token\n",
    "\n",
    "\n",
    "- cp --> logit of the counterfactual token\n",
    "\n",
    "- mem win --> number of factual predictions\n",
    "\n",
    "- cp win --> number of counterfactual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1, fa_heads_subset: ((10, 7),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:19<00:00,  3.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1, fa_heads_subset: ((11, 10),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:19<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1, fa_heads_subset: ((11, 3),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:19<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1, fa_heads_subset: ((10, 7), (11, 10))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:51<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1, fa_heads_subset: ((10, 7), (11, 3))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:51<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1, fa_heads_subset: ((11, 10), (11, 3))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:52<00:00,  4.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1, fa_heads_subset: ((10, 7), (11, 10), (11, 3))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [02:24<00:00,  6.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 5, fa_heads_subset: ((10, 7),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:21<00:00,  3.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 5, fa_heads_subset: ((11, 10),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:20<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 5, fa_heads_subset: ((11, 3),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:25<00:00,  3.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 5, fa_heads_subset: ((10, 7), (11, 10))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:55<00:00,  4.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 5, fa_heads_subset: ((10, 7), (11, 3))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:57<00:00,  4.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 5, fa_heads_subset: ((11, 10), (11, 3))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [02:06<00:00,  5.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 5, fa_heads_subset: ((10, 7), (11, 10), (11, 3))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [02:43<00:00,  6.81s/it]\n"
     ]
    }
   ],
   "source": [
    "result_boost = []\n",
    "for alpha in alphas:\n",
    "    # all subsets of fa heads\n",
    "    for fa_max in range(1, len(fa_heads)+1):\n",
    "        for fa_heads_subset in itertools.combinations(fa_heads, fa_max):\n",
    "            print(f'alpha: {alpha}, fa_heads_subset: {fa_heads_subset}')\n",
    "            ablator.set_heads(heads=list(fa_heads_subset), value=alpha, position='attribute')\n",
    "            \n",
    "            cur_df = ablator.run()\n",
    "            cur_df['alpha'] = alpha\n",
    "            cur_df['heads'] = str(fa_heads_subset)\n",
    "            cur_df['experiment'] = 'boost'\n",
    "            result_boost.append(cur_df)\n",
    "\n",
    "result_boost = pd.concat(result_boost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mem         cp      diff   mem_std    cp_std  diff_std  mem_win  \\\n",
      "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
      "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
      "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
      "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
      "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
      "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
      "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
      "0  14.456228  16.385796 -1.929568  1.665862  2.691089  2.686700   2392.0   \n",
      "0  13.594149  15.910871 -2.316722  1.651094  2.787582  2.762573   1864.0   \n",
      "0  13.966662  17.532597 -3.565933  1.673361  2.688501  2.663716    421.0   \n",
      "0  13.857364  14.130378 -0.273015  1.666047  2.702236  2.729101   5014.0   \n",
      "0  14.439142  16.357597 -1.918455  1.665223  2.691837  2.685108   2419.0   \n",
      "0  13.578178  15.880326 -2.302147  1.650852  2.791918  2.761556   1880.0   \n",
      "0  13.838650  14.100289 -0.261641  1.665650  2.704713  2.727966   5042.0   \n",
      "\n",
      "   cp_win  alpha                         heads experiment  \n",
      "0  9547.0      1                    ((10, 7),)      boost  \n",
      "0  9547.0      1                   ((11, 10),)      boost  \n",
      "0  9547.0      1                    ((11, 3),)      boost  \n",
      "0  9547.0      1           ((10, 7), (11, 10))      boost  \n",
      "0  9547.0      1            ((10, 7), (11, 3))      boost  \n",
      "0  9547.0      1           ((11, 10), (11, 3))      boost  \n",
      "0  9547.0      1  ((10, 7), (11, 10), (11, 3))      boost  \n",
      "0  7495.0      5                    ((10, 7),)      boost  \n",
      "0  8009.0      5                   ((11, 10),)      boost  \n",
      "0  9540.0      5                    ((11, 3),)      boost  \n",
      "0  4614.0      5           ((10, 7), (11, 10))      boost  \n",
      "0  7470.0      5            ((10, 7), (11, 3))      boost  \n",
      "0  7989.0      5           ((11, 10), (11, 3))      boost  \n",
      "0  4579.0      5  ((10, 7), (11, 10), (11, 3))      boost  \n"
     ]
    }
   ],
   "source": [
    "print(result_boost) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((7, 10),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:20<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((9, 9),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:23<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((9, 6),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:21<00:00,  3.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((10, 0),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:20<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((7, 10), (9, 9))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:52<00:00,  4.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((7, 10), (9, 6))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:52<00:00,  4.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((7, 10), (10, 0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:53<00:00,  4.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((9, 9), (9, 6))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:53<00:00,  4.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((9, 9), (10, 0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:52<00:00,  4.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((9, 6), (10, 0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:51<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((7, 10), (9, 9), (9, 6))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [02:18<00:00,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((7, 10), (9, 9), (10, 0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [02:25<00:00,  6.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((7, 10), (9, 6), (10, 0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [02:45<00:00,  6.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((9, 9), (9, 6), (10, 0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [03:23<00:00,  8.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0, cofa_heads_subset: ((7, 10), (9, 9), (9, 6), (10, 0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [02:56<00:00,  7.34s/it]\n"
     ]
    }
   ],
   "source": [
    "result_surpress = []\n",
    "# for beta in betas:\n",
    "    # all subsets of cofa heads\n",
    "for cofa_max in range(1, len(cofa_heads)+1):\n",
    "    for cofa_heads_subset in itertools.combinations(cofa_heads, cofa_max):\n",
    "        print(f'beta: {0}, cofa_heads_subset: {cofa_heads_subset}')\n",
    "        ablator.set_heads(heads=list(cofa_heads_subset), value=0, position='attribute')\n",
    "        cur_df = ablator.run()\n",
    "        cur_df['beta'] = 0\n",
    "        cur_df['heads'] = str(cofa_heads_subset)\n",
    "        cur_df['experiment'] = 'surpress'\n",
    "        result_surpress.append(cur_df)\n",
    "\n",
    "result_surpress = pd.concat(result_surpress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mem</th>\n",
       "      <th>cp</th>\n",
       "      <th>diff</th>\n",
       "      <th>mem_std</th>\n",
       "      <th>cp_std</th>\n",
       "      <th>diff_std</th>\n",
       "      <th>mem_win</th>\n",
       "      <th>cp_win</th>\n",
       "      <th>alpha</th>\n",
       "      <th>heads</th>\n",
       "      <th>experiment</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.981473</td>\n",
       "      <td>17.561539</td>\n",
       "      <td>-3.580064</td>\n",
       "      <td>1.674214</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>2.665300</td>\n",
       "      <td>413.0</td>\n",
       "      <td>9547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((10, 7),)</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.981473</td>\n",
       "      <td>17.561539</td>\n",
       "      <td>-3.580064</td>\n",
       "      <td>1.674214</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>2.665300</td>\n",
       "      <td>413.0</td>\n",
       "      <td>9547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((11, 10),)</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.981473</td>\n",
       "      <td>17.561539</td>\n",
       "      <td>-3.580064</td>\n",
       "      <td>1.674214</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>2.665300</td>\n",
       "      <td>413.0</td>\n",
       "      <td>9547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((11, 3),)</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.981473</td>\n",
       "      <td>17.561539</td>\n",
       "      <td>-3.580064</td>\n",
       "      <td>1.674214</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>2.665300</td>\n",
       "      <td>413.0</td>\n",
       "      <td>9547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((10, 7), (11, 10))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.981473</td>\n",
       "      <td>17.561539</td>\n",
       "      <td>-3.580064</td>\n",
       "      <td>1.674214</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>2.665300</td>\n",
       "      <td>413.0</td>\n",
       "      <td>9547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((10, 7), (11, 3))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.981473</td>\n",
       "      <td>17.561539</td>\n",
       "      <td>-3.580064</td>\n",
       "      <td>1.674214</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>2.665300</td>\n",
       "      <td>413.0</td>\n",
       "      <td>9547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((11, 10), (11, 3))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.981473</td>\n",
       "      <td>17.561539</td>\n",
       "      <td>-3.580064</td>\n",
       "      <td>1.674214</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>2.665300</td>\n",
       "      <td>413.0</td>\n",
       "      <td>9547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((10, 7), (11, 10), (11, 3))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.456228</td>\n",
       "      <td>16.385796</td>\n",
       "      <td>-1.929568</td>\n",
       "      <td>1.665862</td>\n",
       "      <td>2.691089</td>\n",
       "      <td>2.686700</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>7495.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>((10, 7),)</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.594149</td>\n",
       "      <td>15.910871</td>\n",
       "      <td>-2.316722</td>\n",
       "      <td>1.651094</td>\n",
       "      <td>2.787582</td>\n",
       "      <td>2.762573</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>8009.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>((11, 10),)</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.966662</td>\n",
       "      <td>17.532597</td>\n",
       "      <td>-3.565933</td>\n",
       "      <td>1.673361</td>\n",
       "      <td>2.688501</td>\n",
       "      <td>2.663716</td>\n",
       "      <td>421.0</td>\n",
       "      <td>9540.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>((11, 3),)</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.857364</td>\n",
       "      <td>14.130378</td>\n",
       "      <td>-0.273015</td>\n",
       "      <td>1.666047</td>\n",
       "      <td>2.702236</td>\n",
       "      <td>2.729101</td>\n",
       "      <td>5014.0</td>\n",
       "      <td>4614.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>((10, 7), (11, 10))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.439142</td>\n",
       "      <td>16.357597</td>\n",
       "      <td>-1.918455</td>\n",
       "      <td>1.665223</td>\n",
       "      <td>2.691837</td>\n",
       "      <td>2.685108</td>\n",
       "      <td>2419.0</td>\n",
       "      <td>7470.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>((10, 7), (11, 3))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.578178</td>\n",
       "      <td>15.880326</td>\n",
       "      <td>-2.302147</td>\n",
       "      <td>1.650852</td>\n",
       "      <td>2.791918</td>\n",
       "      <td>2.761556</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>7989.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>((11, 10), (11, 3))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.838650</td>\n",
       "      <td>14.100289</td>\n",
       "      <td>-0.261641</td>\n",
       "      <td>1.665650</td>\n",
       "      <td>2.704713</td>\n",
       "      <td>2.727966</td>\n",
       "      <td>5042.0</td>\n",
       "      <td>4579.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>((10, 7), (11, 10), (11, 3))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.295341</td>\n",
       "      <td>17.379835</td>\n",
       "      <td>-3.084497</td>\n",
       "      <td>1.686983</td>\n",
       "      <td>2.501286</td>\n",
       "      <td>2.536508</td>\n",
       "      <td>585.0</td>\n",
       "      <td>9367.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10),)</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.301937</td>\n",
       "      <td>17.501671</td>\n",
       "      <td>-3.199732</td>\n",
       "      <td>1.711332</td>\n",
       "      <td>2.665028</td>\n",
       "      <td>2.580488</td>\n",
       "      <td>613.0</td>\n",
       "      <td>9337.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((9, 9),)</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.992841</td>\n",
       "      <td>17.671854</td>\n",
       "      <td>-3.679014</td>\n",
       "      <td>1.744448</td>\n",
       "      <td>2.708357</td>\n",
       "      <td>2.742359</td>\n",
       "      <td>419.0</td>\n",
       "      <td>9546.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((9, 6),)</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.532300</td>\n",
       "      <td>17.067745</td>\n",
       "      <td>-2.535445</td>\n",
       "      <td>1.582479</td>\n",
       "      <td>2.740251</td>\n",
       "      <td>2.591399</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>8660.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((10, 0),)</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.697640</td>\n",
       "      <td>17.198021</td>\n",
       "      <td>-2.500379</td>\n",
       "      <td>1.735259</td>\n",
       "      <td>2.422641</td>\n",
       "      <td>2.392440</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>8883.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10), (9, 9))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.308892</td>\n",
       "      <td>17.484802</td>\n",
       "      <td>-3.175911</td>\n",
       "      <td>1.772174</td>\n",
       "      <td>2.536055</td>\n",
       "      <td>2.640532</td>\n",
       "      <td>621.0</td>\n",
       "      <td>9340.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10), (9, 6))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.784473</td>\n",
       "      <td>16.912218</td>\n",
       "      <td>-2.127743</td>\n",
       "      <td>1.617704</td>\n",
       "      <td>2.559935</td>\n",
       "      <td>2.480468</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>8264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10), (10, 0))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.301565</td>\n",
       "      <td>17.627138</td>\n",
       "      <td>-3.325571</td>\n",
       "      <td>1.781760</td>\n",
       "      <td>2.691716</td>\n",
       "      <td>2.673940</td>\n",
       "      <td>628.0</td>\n",
       "      <td>9329.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((9, 9), (9, 6))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.940478</td>\n",
       "      <td>16.935949</td>\n",
       "      <td>-1.995473</td>\n",
       "      <td>1.608245</td>\n",
       "      <td>2.714041</td>\n",
       "      <td>2.436320</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>8041.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((9, 9), (10, 0))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.790460</td>\n",
       "      <td>16.965483</td>\n",
       "      <td>-2.175023</td>\n",
       "      <td>1.611213</td>\n",
       "      <td>2.800537</td>\n",
       "      <td>2.645887</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>8098.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((9, 6), (10, 0))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.701550</td>\n",
       "      <td>17.322069</td>\n",
       "      <td>-2.620520</td>\n",
       "      <td>1.819500</td>\n",
       "      <td>2.463759</td>\n",
       "      <td>2.521231</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>8837.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10), (9, 9), (9, 6))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.271722</td>\n",
       "      <td>16.640741</td>\n",
       "      <td>-1.369017</td>\n",
       "      <td>1.653498</td>\n",
       "      <td>2.472515</td>\n",
       "      <td>2.259301</td>\n",
       "      <td>2819.0</td>\n",
       "      <td>7070.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10), (9, 9), (10, 0))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.069153</td>\n",
       "      <td>16.766884</td>\n",
       "      <td>-1.697729</td>\n",
       "      <td>1.660224</td>\n",
       "      <td>2.633436</td>\n",
       "      <td>2.545726</td>\n",
       "      <td>2508.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10), (9, 6), (10, 0))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.199148</td>\n",
       "      <td>16.834558</td>\n",
       "      <td>-1.635410</td>\n",
       "      <td>1.655968</td>\n",
       "      <td>2.781365</td>\n",
       "      <td>2.522774</td>\n",
       "      <td>2608.0</td>\n",
       "      <td>7288.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((9, 9), (9, 6), (10, 0))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.558090</td>\n",
       "      <td>16.491285</td>\n",
       "      <td>-0.933195</td>\n",
       "      <td>1.716989</td>\n",
       "      <td>2.559675</td>\n",
       "      <td>2.379043</td>\n",
       "      <td>3878.0</td>\n",
       "      <td>6010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10), (9, 9), (9, 6), (10, 0))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mem         cp      diff   mem_std    cp_std  diff_std  mem_win  \\\n",
       "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
       "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
       "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
       "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
       "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
       "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
       "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
       "0  14.456228  16.385796 -1.929568  1.665862  2.691089  2.686700   2392.0   \n",
       "0  13.594149  15.910871 -2.316722  1.651094  2.787582  2.762573   1864.0   \n",
       "0  13.966662  17.532597 -3.565933  1.673361  2.688501  2.663716    421.0   \n",
       "0  13.857364  14.130378 -0.273015  1.666047  2.702236  2.729101   5014.0   \n",
       "0  14.439142  16.357597 -1.918455  1.665223  2.691837  2.685108   2419.0   \n",
       "0  13.578178  15.880326 -2.302147  1.650852  2.791918  2.761556   1880.0   \n",
       "0  13.838650  14.100289 -0.261641  1.665650  2.704713  2.727966   5042.0   \n",
       "0  14.295341  17.379835 -3.084497  1.686983  2.501286  2.536508    585.0   \n",
       "0  14.301937  17.501671 -3.199732  1.711332  2.665028  2.580488    613.0   \n",
       "0  13.992841  17.671854 -3.679014  1.744448  2.708357  2.742359    419.0   \n",
       "0  14.532300  17.067745 -2.535445  1.582479  2.740251  2.591399   1274.0   \n",
       "0  14.697640  17.198021 -2.500379  1.735259  2.422641  2.392440   1048.0   \n",
       "0  14.308892  17.484802 -3.175911  1.772174  2.536055  2.640532    621.0   \n",
       "0  14.784473  16.912218 -2.127743  1.617704  2.559935  2.480468   1658.0   \n",
       "0  14.301565  17.627138 -3.325571  1.781760  2.691716  2.673940    628.0   \n",
       "0  14.940478  16.935949 -1.995473  1.608245  2.714041  2.436320   1868.0   \n",
       "0  14.790460  16.965483 -2.175023  1.611213  2.800537  2.645887   1817.0   \n",
       "0  14.701550  17.322069 -2.620520  1.819500  2.463759  2.521231   1106.0   \n",
       "0  15.271722  16.640741 -1.369017  1.653498  2.472515  2.259301   2819.0   \n",
       "0  15.069153  16.766884 -1.697729  1.660224  2.633436  2.545726   2508.0   \n",
       "0  15.199148  16.834558 -1.635410  1.655968  2.781365  2.522774   2608.0   \n",
       "0  15.558090  16.491285 -0.933195  1.716989  2.559675  2.379043   3878.0   \n",
       "\n",
       "   cp_win  alpha                               heads experiment  beta  \n",
       "0  9547.0    1.0                          ((10, 7),)      boost   NaN  \n",
       "0  9547.0    1.0                         ((11, 10),)      boost   NaN  \n",
       "0  9547.0    1.0                          ((11, 3),)      boost   NaN  \n",
       "0  9547.0    1.0                 ((10, 7), (11, 10))      boost   NaN  \n",
       "0  9547.0    1.0                  ((10, 7), (11, 3))      boost   NaN  \n",
       "0  9547.0    1.0                 ((11, 10), (11, 3))      boost   NaN  \n",
       "0  9547.0    1.0        ((10, 7), (11, 10), (11, 3))      boost   NaN  \n",
       "0  7495.0    5.0                          ((10, 7),)      boost   NaN  \n",
       "0  8009.0    5.0                         ((11, 10),)      boost   NaN  \n",
       "0  9540.0    5.0                          ((11, 3),)      boost   NaN  \n",
       "0  4614.0    5.0                 ((10, 7), (11, 10))      boost   NaN  \n",
       "0  7470.0    5.0                  ((10, 7), (11, 3))      boost   NaN  \n",
       "0  7989.0    5.0                 ((11, 10), (11, 3))      boost   NaN  \n",
       "0  4579.0    5.0        ((10, 7), (11, 10), (11, 3))      boost   NaN  \n",
       "0  9367.0    NaN                          ((7, 10),)   surpress   0.0  \n",
       "0  9337.0    NaN                           ((9, 9),)   surpress   0.0  \n",
       "0  9546.0    NaN                           ((9, 6),)   surpress   0.0  \n",
       "0  8660.0    NaN                          ((10, 0),)   surpress   0.0  \n",
       "0  8883.0    NaN                   ((7, 10), (9, 9))   surpress   0.0  \n",
       "0  9340.0    NaN                   ((7, 10), (9, 6))   surpress   0.0  \n",
       "0  8264.0    NaN                  ((7, 10), (10, 0))   surpress   0.0  \n",
       "0  9329.0    NaN                    ((9, 9), (9, 6))   surpress   0.0  \n",
       "0  8041.0    NaN                   ((9, 9), (10, 0))   surpress   0.0  \n",
       "0  8098.0    NaN                   ((9, 6), (10, 0))   surpress   0.0  \n",
       "0  8837.0    NaN           ((7, 10), (9, 9), (9, 6))   surpress   0.0  \n",
       "0  7070.0    NaN          ((7, 10), (9, 9), (10, 0))   surpress   0.0  \n",
       "0  7400.0    NaN          ((7, 10), (9, 6), (10, 0))   surpress   0.0  \n",
       "0  7288.0    NaN           ((9, 9), (9, 6), (10, 0))   surpress   0.0  \n",
       "0  6010.0    NaN  ((7, 10), (9, 9), (9, 6), (10, 0))   surpress   0.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([result_boost, result_surpress])\n",
    "data.to_csv('results_boost_surpress.csv', index=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [05:01<00:00, 12.57s/it]\n",
      "Ablating: 100%|██████████| 24/24 [04:34<00:00, 11.46s/it]\n",
      "Ablating: 100%|██████████| 24/24 [04:32<00:00, 11.37s/it]\n",
      "Ablating: 100%|██████████| 24/24 [04:27<00:00, 11.16s/it]\n",
      "Ablating: 100%|██████████| 24/24 [03:12<00:00,  8.02s/it]\n",
      "Ablating: 100%|██████████| 24/24 [03:12<00:00,  8.00s/it]\n"
     ]
    }
   ],
   "source": [
    "best_boost = [((10, 7), (11, 10), (11, 3)), ((10, 7), (11, 10))]\n",
    "best_surpress = [((7, 10), (9, 9), (9, 6), (10, 0)), ((7, 10), (9, 9), (10, 0)), ((9, 9), (9, 6), (10, 0))]\n",
    "combined_result = []\n",
    "for bost in best_boost:\n",
    "    for surpress in best_surpress:\n",
    "        ablator.set_heads(heads=list(bost), value=5, position='attribute')\n",
    "        ablator.set_heads(heads=list(surpress), value=0, position='attribute', reset=False)\n",
    "        cur_df = ablator.run()\n",
    "        cur_df['experiment'] = 'combined'\n",
    "        cur_df['heads_boost'] = str(bost)\n",
    "        cur_df['beta'] = 0\n",
    "        cur_df['alpha'] = 5\n",
    "        cur_df['heads_surpress'] = str(surpress)\n",
    "        combined_result.append(cur_df)\n",
    "\n",
    "combined_result = pd.concat(combined_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mem</th>\n",
       "      <th>cp</th>\n",
       "      <th>diff</th>\n",
       "      <th>mem_std</th>\n",
       "      <th>cp_std</th>\n",
       "      <th>diff_std</th>\n",
       "      <th>mem_win</th>\n",
       "      <th>cp_win</th>\n",
       "      <th>alpha</th>\n",
       "      <th>heads</th>\n",
       "      <th>experiment</th>\n",
       "      <th>beta</th>\n",
       "      <th>heads_boost</th>\n",
       "      <th>heads_surpress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.981473</td>\n",
       "      <td>17.561539</td>\n",
       "      <td>-3.580064</td>\n",
       "      <td>1.674214</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>2.665300</td>\n",
       "      <td>413.0</td>\n",
       "      <td>9547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((10, 7),)</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.981473</td>\n",
       "      <td>17.561539</td>\n",
       "      <td>-3.580064</td>\n",
       "      <td>1.674214</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>2.665300</td>\n",
       "      <td>413.0</td>\n",
       "      <td>9547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((11, 10),)</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.981473</td>\n",
       "      <td>17.561539</td>\n",
       "      <td>-3.580064</td>\n",
       "      <td>1.674214</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>2.665300</td>\n",
       "      <td>413.0</td>\n",
       "      <td>9547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((11, 3),)</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.981473</td>\n",
       "      <td>17.561539</td>\n",
       "      <td>-3.580064</td>\n",
       "      <td>1.674214</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>2.665300</td>\n",
       "      <td>413.0</td>\n",
       "      <td>9547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((10, 7), (11, 10))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.981473</td>\n",
       "      <td>17.561539</td>\n",
       "      <td>-3.580064</td>\n",
       "      <td>1.674214</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>2.665300</td>\n",
       "      <td>413.0</td>\n",
       "      <td>9547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((10, 7), (11, 3))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.981473</td>\n",
       "      <td>17.561539</td>\n",
       "      <td>-3.580064</td>\n",
       "      <td>1.674214</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>2.665300</td>\n",
       "      <td>413.0</td>\n",
       "      <td>9547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((11, 10), (11, 3))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.981473</td>\n",
       "      <td>17.561539</td>\n",
       "      <td>-3.580064</td>\n",
       "      <td>1.674214</td>\n",
       "      <td>2.685192</td>\n",
       "      <td>2.665300</td>\n",
       "      <td>413.0</td>\n",
       "      <td>9547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((10, 7), (11, 10), (11, 3))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.456228</td>\n",
       "      <td>16.385796</td>\n",
       "      <td>-1.929568</td>\n",
       "      <td>1.665862</td>\n",
       "      <td>2.691089</td>\n",
       "      <td>2.686700</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>7495.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>((10, 7),)</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.594149</td>\n",
       "      <td>15.910871</td>\n",
       "      <td>-2.316722</td>\n",
       "      <td>1.651094</td>\n",
       "      <td>2.787582</td>\n",
       "      <td>2.762573</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>8009.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>((11, 10),)</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.966662</td>\n",
       "      <td>17.532597</td>\n",
       "      <td>-3.565933</td>\n",
       "      <td>1.673361</td>\n",
       "      <td>2.688501</td>\n",
       "      <td>2.663716</td>\n",
       "      <td>421.0</td>\n",
       "      <td>9540.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>((11, 3),)</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.857364</td>\n",
       "      <td>14.130378</td>\n",
       "      <td>-0.273015</td>\n",
       "      <td>1.666047</td>\n",
       "      <td>2.702236</td>\n",
       "      <td>2.729101</td>\n",
       "      <td>5014.0</td>\n",
       "      <td>4614.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>((10, 7), (11, 10))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.439142</td>\n",
       "      <td>16.357597</td>\n",
       "      <td>-1.918455</td>\n",
       "      <td>1.665223</td>\n",
       "      <td>2.691837</td>\n",
       "      <td>2.685108</td>\n",
       "      <td>2419.0</td>\n",
       "      <td>7470.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>((10, 7), (11, 3))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.578178</td>\n",
       "      <td>15.880326</td>\n",
       "      <td>-2.302147</td>\n",
       "      <td>1.650852</td>\n",
       "      <td>2.791918</td>\n",
       "      <td>2.761556</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>7989.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>((11, 10), (11, 3))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.838650</td>\n",
       "      <td>14.100289</td>\n",
       "      <td>-0.261641</td>\n",
       "      <td>1.665650</td>\n",
       "      <td>2.704713</td>\n",
       "      <td>2.727966</td>\n",
       "      <td>5042.0</td>\n",
       "      <td>4579.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>((10, 7), (11, 10), (11, 3))</td>\n",
       "      <td>boost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.295341</td>\n",
       "      <td>17.379835</td>\n",
       "      <td>-3.084497</td>\n",
       "      <td>1.686983</td>\n",
       "      <td>2.501286</td>\n",
       "      <td>2.536508</td>\n",
       "      <td>585.0</td>\n",
       "      <td>9367.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10),)</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.301937</td>\n",
       "      <td>17.501671</td>\n",
       "      <td>-3.199732</td>\n",
       "      <td>1.711332</td>\n",
       "      <td>2.665028</td>\n",
       "      <td>2.580488</td>\n",
       "      <td>613.0</td>\n",
       "      <td>9337.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((9, 9),)</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.992841</td>\n",
       "      <td>17.671854</td>\n",
       "      <td>-3.679014</td>\n",
       "      <td>1.744448</td>\n",
       "      <td>2.708357</td>\n",
       "      <td>2.742359</td>\n",
       "      <td>419.0</td>\n",
       "      <td>9546.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((9, 6),)</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.532300</td>\n",
       "      <td>17.067745</td>\n",
       "      <td>-2.535445</td>\n",
       "      <td>1.582479</td>\n",
       "      <td>2.740251</td>\n",
       "      <td>2.591399</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>8660.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((10, 0),)</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.697640</td>\n",
       "      <td>17.198021</td>\n",
       "      <td>-2.500379</td>\n",
       "      <td>1.735259</td>\n",
       "      <td>2.422641</td>\n",
       "      <td>2.392440</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>8883.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10), (9, 9))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.308892</td>\n",
       "      <td>17.484802</td>\n",
       "      <td>-3.175911</td>\n",
       "      <td>1.772174</td>\n",
       "      <td>2.536055</td>\n",
       "      <td>2.640532</td>\n",
       "      <td>621.0</td>\n",
       "      <td>9340.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10), (9, 6))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.784473</td>\n",
       "      <td>16.912218</td>\n",
       "      <td>-2.127743</td>\n",
       "      <td>1.617704</td>\n",
       "      <td>2.559935</td>\n",
       "      <td>2.480468</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>8264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10), (10, 0))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.301565</td>\n",
       "      <td>17.627138</td>\n",
       "      <td>-3.325571</td>\n",
       "      <td>1.781760</td>\n",
       "      <td>2.691716</td>\n",
       "      <td>2.673940</td>\n",
       "      <td>628.0</td>\n",
       "      <td>9329.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((9, 9), (9, 6))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.940478</td>\n",
       "      <td>16.935949</td>\n",
       "      <td>-1.995473</td>\n",
       "      <td>1.608245</td>\n",
       "      <td>2.714041</td>\n",
       "      <td>2.436320</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>8041.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((9, 9), (10, 0))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.790460</td>\n",
       "      <td>16.965483</td>\n",
       "      <td>-2.175023</td>\n",
       "      <td>1.611213</td>\n",
       "      <td>2.800537</td>\n",
       "      <td>2.645887</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>8098.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((9, 6), (10, 0))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.701550</td>\n",
       "      <td>17.322069</td>\n",
       "      <td>-2.620520</td>\n",
       "      <td>1.819500</td>\n",
       "      <td>2.463759</td>\n",
       "      <td>2.521231</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>8837.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10), (9, 9), (9, 6))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.271722</td>\n",
       "      <td>16.640741</td>\n",
       "      <td>-1.369017</td>\n",
       "      <td>1.653498</td>\n",
       "      <td>2.472515</td>\n",
       "      <td>2.259301</td>\n",
       "      <td>2819.0</td>\n",
       "      <td>7070.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10), (9, 9), (10, 0))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.069153</td>\n",
       "      <td>16.766884</td>\n",
       "      <td>-1.697729</td>\n",
       "      <td>1.660224</td>\n",
       "      <td>2.633436</td>\n",
       "      <td>2.545726</td>\n",
       "      <td>2508.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10), (9, 6), (10, 0))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.199148</td>\n",
       "      <td>16.834558</td>\n",
       "      <td>-1.635410</td>\n",
       "      <td>1.655968</td>\n",
       "      <td>2.781365</td>\n",
       "      <td>2.522774</td>\n",
       "      <td>2608.0</td>\n",
       "      <td>7288.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((9, 9), (9, 6), (10, 0))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.558090</td>\n",
       "      <td>16.491285</td>\n",
       "      <td>-0.933195</td>\n",
       "      <td>1.716989</td>\n",
       "      <td>2.559675</td>\n",
       "      <td>2.379043</td>\n",
       "      <td>3878.0</td>\n",
       "      <td>6010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>((7, 10), (9, 9), (9, 6), (10, 0))</td>\n",
       "      <td>surpress</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.385982</td>\n",
       "      <td>12.946010</td>\n",
       "      <td>2.439970</td>\n",
       "      <td>1.745049</td>\n",
       "      <td>2.787324</td>\n",
       "      <td>2.751831</td>\n",
       "      <td>7862.0</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>combined</td>\n",
       "      <td>0.0</td>\n",
       "      <td>((10, 7), (11, 10), (11, 3))</td>\n",
       "      <td>((7, 10), (9, 9), (9, 6), (10, 0))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.066147</td>\n",
       "      <td>12.857540</td>\n",
       "      <td>2.208606</td>\n",
       "      <td>1.685526</td>\n",
       "      <td>2.568035</td>\n",
       "      <td>2.519094</td>\n",
       "      <td>7738.0</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>combined</td>\n",
       "      <td>0.0</td>\n",
       "      <td>((10, 7), (11, 10), (11, 3))</td>\n",
       "      <td>((7, 10), (9, 9), (10, 0))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.020924</td>\n",
       "      <td>13.130342</td>\n",
       "      <td>1.890582</td>\n",
       "      <td>1.674435</td>\n",
       "      <td>2.952828</td>\n",
       "      <td>2.797500</td>\n",
       "      <td>7435.0</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>combined</td>\n",
       "      <td>0.0</td>\n",
       "      <td>((10, 7), (11, 10), (11, 3))</td>\n",
       "      <td>((9, 9), (9, 6), (10, 0))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.410898</td>\n",
       "      <td>12.896770</td>\n",
       "      <td>2.514130</td>\n",
       "      <td>1.740880</td>\n",
       "      <td>2.849144</td>\n",
       "      <td>2.791324</td>\n",
       "      <td>7881.0</td>\n",
       "      <td>1579.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>combined</td>\n",
       "      <td>0.0</td>\n",
       "      <td>((10, 7), (11, 10))</td>\n",
       "      <td>((7, 10), (9, 9), (9, 6), (10, 0))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.091547</td>\n",
       "      <td>12.849116</td>\n",
       "      <td>2.242429</td>\n",
       "      <td>1.680636</td>\n",
       "      <td>2.595985</td>\n",
       "      <td>2.526749</td>\n",
       "      <td>7763.0</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>combined</td>\n",
       "      <td>0.0</td>\n",
       "      <td>((10, 7), (11, 10))</td>\n",
       "      <td>((7, 10), (9, 9), (10, 0))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.046713</td>\n",
       "      <td>13.077932</td>\n",
       "      <td>1.968780</td>\n",
       "      <td>1.669838</td>\n",
       "      <td>3.013070</td>\n",
       "      <td>2.842006</td>\n",
       "      <td>7474.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>combined</td>\n",
       "      <td>0.0</td>\n",
       "      <td>((10, 7), (11, 10))</td>\n",
       "      <td>((9, 9), (9, 6), (10, 0))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mem         cp      diff   mem_std    cp_std  diff_std  mem_win  \\\n",
       "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
       "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
       "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
       "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
       "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
       "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
       "0  13.981473  17.561539 -3.580064  1.674214  2.685192  2.665300    413.0   \n",
       "0  14.456228  16.385796 -1.929568  1.665862  2.691089  2.686700   2392.0   \n",
       "0  13.594149  15.910871 -2.316722  1.651094  2.787582  2.762573   1864.0   \n",
       "0  13.966662  17.532597 -3.565933  1.673361  2.688501  2.663716    421.0   \n",
       "0  13.857364  14.130378 -0.273015  1.666047  2.702236  2.729101   5014.0   \n",
       "0  14.439142  16.357597 -1.918455  1.665223  2.691837  2.685108   2419.0   \n",
       "0  13.578178  15.880326 -2.302147  1.650852  2.791918  2.761556   1880.0   \n",
       "0  13.838650  14.100289 -0.261641  1.665650  2.704713  2.727966   5042.0   \n",
       "0  14.295341  17.379835 -3.084497  1.686983  2.501286  2.536508    585.0   \n",
       "0  14.301937  17.501671 -3.199732  1.711332  2.665028  2.580488    613.0   \n",
       "0  13.992841  17.671854 -3.679014  1.744448  2.708357  2.742359    419.0   \n",
       "0  14.532300  17.067745 -2.535445  1.582479  2.740251  2.591399   1274.0   \n",
       "0  14.697640  17.198021 -2.500379  1.735259  2.422641  2.392440   1048.0   \n",
       "0  14.308892  17.484802 -3.175911  1.772174  2.536055  2.640532    621.0   \n",
       "0  14.784473  16.912218 -2.127743  1.617704  2.559935  2.480468   1658.0   \n",
       "0  14.301565  17.627138 -3.325571  1.781760  2.691716  2.673940    628.0   \n",
       "0  14.940478  16.935949 -1.995473  1.608245  2.714041  2.436320   1868.0   \n",
       "0  14.790460  16.965483 -2.175023  1.611213  2.800537  2.645887   1817.0   \n",
       "0  14.701550  17.322069 -2.620520  1.819500  2.463759  2.521231   1106.0   \n",
       "0  15.271722  16.640741 -1.369017  1.653498  2.472515  2.259301   2819.0   \n",
       "0  15.069153  16.766884 -1.697729  1.660224  2.633436  2.545726   2508.0   \n",
       "0  15.199148  16.834558 -1.635410  1.655968  2.781365  2.522774   2608.0   \n",
       "0  15.558090  16.491285 -0.933195  1.716989  2.559675  2.379043   3878.0   \n",
       "0  15.385982  12.946010  2.439970  1.745049  2.787324  2.751831   7862.0   \n",
       "0  15.066147  12.857540  2.208606  1.685526  2.568035  2.519094   7738.0   \n",
       "0  15.020924  13.130342  1.890582  1.674435  2.952828  2.797500   7435.0   \n",
       "0  15.410898  12.896770  2.514130  1.740880  2.849144  2.791324   7881.0   \n",
       "0  15.091547  12.849116  2.242429  1.680636  2.595985  2.526749   7763.0   \n",
       "0  15.046713  13.077932  1.968780  1.669838  3.013070  2.842006   7474.0   \n",
       "\n",
       "   cp_win  alpha                               heads experiment  beta  \\\n",
       "0  9547.0    1.0                          ((10, 7),)      boost   NaN   \n",
       "0  9547.0    1.0                         ((11, 10),)      boost   NaN   \n",
       "0  9547.0    1.0                          ((11, 3),)      boost   NaN   \n",
       "0  9547.0    1.0                 ((10, 7), (11, 10))      boost   NaN   \n",
       "0  9547.0    1.0                  ((10, 7), (11, 3))      boost   NaN   \n",
       "0  9547.0    1.0                 ((11, 10), (11, 3))      boost   NaN   \n",
       "0  9547.0    1.0        ((10, 7), (11, 10), (11, 3))      boost   NaN   \n",
       "0  7495.0    5.0                          ((10, 7),)      boost   NaN   \n",
       "0  8009.0    5.0                         ((11, 10),)      boost   NaN   \n",
       "0  9540.0    5.0                          ((11, 3),)      boost   NaN   \n",
       "0  4614.0    5.0                 ((10, 7), (11, 10))      boost   NaN   \n",
       "0  7470.0    5.0                  ((10, 7), (11, 3))      boost   NaN   \n",
       "0  7989.0    5.0                 ((11, 10), (11, 3))      boost   NaN   \n",
       "0  4579.0    5.0        ((10, 7), (11, 10), (11, 3))      boost   NaN   \n",
       "0  9367.0    NaN                          ((7, 10),)   surpress   0.0   \n",
       "0  9337.0    NaN                           ((9, 9),)   surpress   0.0   \n",
       "0  9546.0    NaN                           ((9, 6),)   surpress   0.0   \n",
       "0  8660.0    NaN                          ((10, 0),)   surpress   0.0   \n",
       "0  8883.0    NaN                   ((7, 10), (9, 9))   surpress   0.0   \n",
       "0  9340.0    NaN                   ((7, 10), (9, 6))   surpress   0.0   \n",
       "0  8264.0    NaN                  ((7, 10), (10, 0))   surpress   0.0   \n",
       "0  9329.0    NaN                    ((9, 9), (9, 6))   surpress   0.0   \n",
       "0  8041.0    NaN                   ((9, 9), (10, 0))   surpress   0.0   \n",
       "0  8098.0    NaN                   ((9, 6), (10, 0))   surpress   0.0   \n",
       "0  8837.0    NaN           ((7, 10), (9, 9), (9, 6))   surpress   0.0   \n",
       "0  7070.0    NaN          ((7, 10), (9, 9), (10, 0))   surpress   0.0   \n",
       "0  7400.0    NaN          ((7, 10), (9, 6), (10, 0))   surpress   0.0   \n",
       "0  7288.0    NaN           ((9, 9), (9, 6), (10, 0))   surpress   0.0   \n",
       "0  6010.0    NaN  ((7, 10), (9, 9), (9, 6), (10, 0))   surpress   0.0   \n",
       "0  1591.0    5.0                                 NaN   combined   0.0   \n",
       "0  1611.0    5.0                                 NaN   combined   0.0   \n",
       "0  2046.0    5.0                                 NaN   combined   0.0   \n",
       "0  1579.0    5.0                                 NaN   combined   0.0   \n",
       "0  1591.0    5.0                                 NaN   combined   0.0   \n",
       "0  2022.0    5.0                                 NaN   combined   0.0   \n",
       "\n",
       "                    heads_boost                      heads_surpress  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0                           NaN                                 NaN  \n",
       "0  ((10, 7), (11, 10), (11, 3))  ((7, 10), (9, 9), (9, 6), (10, 0))  \n",
       "0  ((10, 7), (11, 10), (11, 3))          ((7, 10), (9, 9), (10, 0))  \n",
       "0  ((10, 7), (11, 10), (11, 3))           ((9, 9), (9, 6), (10, 0))  \n",
       "0           ((10, 7), (11, 10))  ((7, 10), (9, 9), (9, 6), (10, 0))  \n",
       "0           ((10, 7), (11, 10))          ((7, 10), (9, 9), (10, 0))  \n",
       "0           ((10, 7), (11, 10))           ((9, 9), (9, 6), (10, 0))  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([result_boost, result_surpress, combined_result])\n",
    "data.to_csv('results_boost_surpress.csv', index=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../data/ablation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating: 100%|██████████| 24/24 [01:14<00:00,  3.12s/it]\n",
      "Ablating: 100%|██████████| 24/24 [01:14<00:00,  3.09s/it]\n",
      "Ablating: 100%|██████████| 24/24 [01:46<00:00,  4.42s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mem</th>\n",
       "      <th>cp</th>\n",
       "      <th>diff</th>\n",
       "      <th>mem_std</th>\n",
       "      <th>cp_std</th>\n",
       "      <th>diff_std</th>\n",
       "      <th>mem_win</th>\n",
       "      <th>cp_win</th>\n",
       "      <th>experiment</th>\n",
       "      <th>fa_alpha</th>\n",
       "      <th>cofa_alpha</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.532300</td>\n",
       "      <td>17.067745</td>\n",
       "      <td>-2.535445</td>\n",
       "      <td>1.582479</td>\n",
       "      <td>2.740251</td>\n",
       "      <td>2.591399</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>8660.0</td>\n",
       "      <td>individual</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.966662</td>\n",
       "      <td>17.532597</td>\n",
       "      <td>-3.565933</td>\n",
       "      <td>1.673361</td>\n",
       "      <td>2.688501</td>\n",
       "      <td>2.663716</td>\n",
       "      <td>421.0</td>\n",
       "      <td>9540.0</td>\n",
       "      <td>individual</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.509600</td>\n",
       "      <td>17.066998</td>\n",
       "      <td>-2.557397</td>\n",
       "      <td>1.588190</td>\n",
       "      <td>2.716855</td>\n",
       "      <td>2.574206</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>8733.0</td>\n",
       "      <td>individual</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mem         cp      diff   mem_std    cp_std  diff_std  mem_win  \\\n",
       "0  14.532300  17.067745 -2.535445  1.582479  2.740251  2.591399   1274.0   \n",
       "0  13.966662  17.532597 -3.565933  1.673361  2.688501  2.663716    421.0   \n",
       "0  14.509600  17.066998 -2.557397  1.588190  2.716855  2.574206   1205.0   \n",
       "\n",
       "   cp_win  experiment  fa_alpha  cofa_alpha  percentage  \n",
       "0  8660.0  individual         1           0    0.128246  \n",
       "0  9540.0  individual         5           1    0.042265  \n",
       "0  8733.0  individual         5           0    0.121252  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual = []\n",
    "ablator.set_heads(heads=[(10, 0)], value=0, position=\"attribute\") #counter\n",
    "individual.append(ablator.run())\n",
    "\n",
    "\n",
    "ablator.set_heads(heads=[(11, 3)], value=5, position=\"attribute\") #fact\n",
    "individual.append(ablator.run())\n",
    "\n",
    "\n",
    "ablator.set_heads(heads=[(10, 0)], value=0, position=\"attribute\")\n",
    "ablator.set_heads(heads=[(11, 3)], value=5, position=\"attribute\", reset=False)\n",
    "individual.append(ablator.run())\n",
    "\n",
    "individual_data = pd.concat(individual)\n",
    "individual_data[\"experiment\"] = \"individual\"\n",
    "individual_data[\"fa_alpha\"] = [1, 5, 5]\n",
    "individual_data[\"cofa_alpha\"] = [0, 1, 0]\n",
    "individual_data['percentage'] = individual_data['mem_win'] / (individual_data['mem_win'] + individual_data['cp_win']).astype(float)\n",
    "\n",
    "individual_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass to the model your own modification function. You can pass a list of hook (string, function) to the model using set_hooks method. The hooks should be consistent with the hook of the transformer lens library (https://neelnanda-io.github.io/TransformerLens/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [2 1]\n",
      " [4 3]\n",
      " [3 2]\n",
      " [2 1]\n",
      " [0 4]\n",
      " [0 4]\n",
      " [3 3]\n",
      " [0 0]\n",
      " [2 4]]\n",
      "[[ 8 10]\n",
      " [12 10]\n",
      " [10 10]\n",
      " [10 11]\n",
      " [10  9]\n",
      " [10  8]\n",
      " [10 10]\n",
      " [ 8 11]\n",
      " [12  8]\n",
      " [12 12]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ablating:   0%|          | 0/24 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "HookedTransformer.forward() got an unexpected keyword argument 'ruturn_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m head \u001b[38;5;129;01min\u001b[39;00m random_early_heads:\n\u001b[1;32m     13\u001b[0m     ablator\u001b[38;5;241m.\u001b[39mset_heads(heads\u001b[38;5;241m=\u001b[39m[head], value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#fact\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mablator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheads\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(head)\n",
      "File \u001b[0;32m~/FACT-AI-Assignment/original_paper_code/notebooks/../Src/experiment/ablator.py:184\u001b[0m, in \u001b[0;36mAblator.run\u001b[0;34m(self, normalize_logit, save_name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    168\u001b[0m     normalize_logit: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    169\u001b[0m     save_name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    170\u001b[0m ):\n\u001b[1;32m    171\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03m    Run the attention ablation/modification experiment and return the results\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    - cp_win: count of the examples where the model predicted the counterfactual token\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mablate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalize_logit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmem\u001b[39m\u001b[38;5;124m\"\u001b[39m: result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmem\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcp\u001b[39m\u001b[38;5;124m\"\u001b[39m: result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcp\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcp_win\u001b[39m\u001b[38;5;124m\"\u001b[39m: result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcp_win\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    195\u001b[0m     }\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(data, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/FACT-AI-Assignment/original_paper_code/notebooks/../Src/experiment/ablator.py:151\u001b[0m, in \u001b[0;36mAblator.ablate\u001b[0;34m(self, normalize_logit)\u001b[0m\n\u001b[1;32m    149\u001b[0m result \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmem\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcp\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiff\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmem_win\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcp_win\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m length \u001b[38;5;129;01min\u001b[39;00m tqdm(lengths, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAblating\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 151\u001b[0m     mem, cp, diff, mem_win, cp_win \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mablate_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize_logit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmem\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(mem)\n\u001b[1;32m    153\u001b[0m     result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcp\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(cp)\n",
      "File \u001b[0;32m~/FACT-AI-Assignment/original_paper_code/notebooks/../Src/experiment/ablator.py:124\u001b[0m, in \u001b[0;36mAblator.ablate_length\u001b[0;34m(self, length, normalize_logit)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mset_len(length)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m DataLoader(\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset,\n\u001b[1;32m    121\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m    122\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    123\u001b[0m ):\n\u001b[0;32m--> 124\u001b[0m     logit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__run_with_hooks__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     logit_mem, logit_cp, _, _, mem_winner, cp_winner \u001b[38;5;241m=\u001b[39m to_logit_token(\n\u001b[1;32m    126\u001b[0m         logit, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m], normalize\u001b[38;5;241m=\u001b[39mnormalize_logit, return_winners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m     mem\u001b[38;5;241m.\u001b[39mappend(logit_mem)\n",
      "File \u001b[0;32m~/FACT-AI-Assignment/original_paper_code/notebooks/../Src/experiment/ablator.py:101\u001b[0m, in \u001b[0;36mAblator.__run_with_hooks__\u001b[0;34m(self, batch, eval)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook_name, hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks:\n\u001b[1;32m     99\u001b[0m     actual_hooks\u001b[38;5;241m.\u001b[39mappend((hook_name, hook_fn(hook)))\n\u001b[0;32m--> 101\u001b[0m logit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_hooks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_bos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfwd_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactual_hooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logit[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[0;32m~/FACT-AI-Assignment/original_paper_code/notebooks/../Src/model.py:141\u001b[0m, in \u001b[0;36mWrapHookedTransformer.run_with_hooks\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_with_hooks\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fact/lib/python3.10/site-packages/transformer_lens/hook_points.py:365\u001b[0m, in \u001b[0;36mHookedRootModule.run_with_hooks\u001b[0;34m(self, fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING: Hooks will be reset at the end of run_with_hooks. This removes the backward hooks before a backward pass can occur.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m     )\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks(\n\u001b[1;32m    363\u001b[0m     fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts\n\u001b[1;32m    364\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m hooked_model:\n\u001b[0;32m--> 365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhooked_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: HookedTransformer.forward() got an unexpected keyword argument 'ruturn_type'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(34)\n",
    "random_early_heads = np.random.choice(range(5), (10, 2))\n",
    "\n",
    "random_late_heads = np.random.choice(range(8, 13), (10, 2))\n",
    "\n",
    "\n",
    "print(random_early_heads)\n",
    "print(random_late_heads)\n",
    "\n",
    "random = []\n",
    "for head in random_early_heads:\n",
    "    ablator.set_heads(heads=[head], value=5, position=\"attribute\") #fact\n",
    "    df = ablator.run()\n",
    "    df[\"experiment\"] = \"random\"\n",
    "    df[\"heads\"] = str(head)\n",
    "    random.append(df)\n",
    "\n",
    "for head in random_late_heads:\n",
    "    ablator.set_heads(heads=[head], value=5, position=\"attribute\") #fact\n",
    "    df = ablator.run()\n",
    "    df[\"experiment\"] = \"random\"\n",
    "    df[\"heads\"] = str(head)\n",
    "    random.append(df)\n",
    "\n",
    "random_data = pd.concat(random)\n",
    "random_data[\"fa_alpha\"] = 5\n",
    "random_data[\"cofa_alpha\"] = 0\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
